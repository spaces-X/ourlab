package com.dt.spark

import org.apache.spark.SparkConf
import org.apache.spark.SparkContext
import org.apache.spark.SparkConf
object exele {
  val conf = new SparkConf().setMaster("spark://bigdata02:7077").setAppName("ex_ele");
  val sc = new SparkContext(conf);
  val lines = sc.textFile("hdfs://bigdata01:9000/home/guizhou/csv/exlistelec201701.csv")
  val head = lines.take(2)
  var filterline = lines.filter{
    x=>
      val items = x.split(",")
      items(4).length>0 && items(14).length>0 && items(20).length>1 && items(23).length>0 && !head.contains(x)
  }
  filterline = filterline.filter{
    x=>
      val items = x.split(",")
      items(20).length>1 && items(23).toDouble>0
  }
  
  
}